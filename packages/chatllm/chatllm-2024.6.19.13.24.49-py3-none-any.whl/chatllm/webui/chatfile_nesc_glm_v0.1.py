#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : st_chat
# @Time         : 2023/8/11 14:45
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  :

import streamlit as st
# st.set_page_config('ğŸ”¥ChatLLM', layout='wide', initial_sidebar_state='collapsed')

from openai import OpenAI
from meutils.serving.streamlit import hide_st_style, st_chat_message, ChatMessage

hide_st_style()


def gen(question):
    nesc = "\n`å¤§æ¨¡å‹æ ¹æ®å…¬å¸ç›¸å…³æ³•è§„åŠæé—®è¯­ä¹‰åšç­”ï¼Œä¸ä½œä¸ºåˆè§„ç®¡ç†å®˜æ–¹å›å¤ã€‚`"

    data = {

        'model': '65f41c8a9c0ebbcbe28bb9c1',

        'messages': [
            {'role': 'user', 'content': question}
        ],
        'stream': True,

    }
    _ = OpenAI().chat.completions.create(**data)

    for chunk in _:
        if chunk.choices[0].finish_reason == 'stop':
            break
        yield chunk.choices[0].delta.content
    yield from nesc


if __name__ == '__main__':
    col1, col2, col3, *_ = st.columns(3)
    with col1:
        st.image('è§„ä¸ç›¸.png', width=64)
    with col2:
        st.markdown('##### ')
        st.markdown('##### ')
        st.markdown('##### è§„ä¸ç›¸é©¾åˆ°')

    st.markdown('> âš ï¸â€œè§„ä¸ç›¸â€ä»…ä¾›ä¸œåŒ—è¯åˆ¸å†…éƒ¨æµ‹è¯•ä½¿ç”¨ï¼Œæ‰€åšå›ç­”ä¸å¾—ç”¨äºä¸œåŒ—è¯åˆ¸å®˜æ–¹å›å¤ã€‚')

    st_chat_message(ChatMessage(avatar="è§„ä¸ç›¸.png", generator="æ¬¢è¿æ¥æ‰¾**è§„ä¸ç›¸**ï¼Œæ‚¨æœ‰ä»€ä¹ˆè¦å’¨è¯¢çš„å—â“"))

    for message in st.session_state.messages:  # è®¾è®¡his
        st_chat_message(message)

    print(st.session_state.messages)

    prompt = st.chat_input("    ğŸ¤” ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜", key='xx')  # æœ€ä¸‹é¢
    if prompt:
        with st.spinner('AI ğŸ¤”'):
            st_chat_message(ChatMessage(name="user", generator=prompt), is_history=True)

            st_chat_message(ChatMessage(avatar="è§„ä¸ç›¸.png", generator=gen(prompt)), is_history=True)
