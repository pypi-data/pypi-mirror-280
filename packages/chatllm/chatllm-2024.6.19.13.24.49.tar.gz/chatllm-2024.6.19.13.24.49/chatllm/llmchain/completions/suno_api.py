#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : suno_api
# @Time         : 2024/4/3 16:46
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  : https://suno.gcui.art/docs


from meutils.pipe import *

base_url = os.getenv("SUNO_BASE_URL")


def custom_generate_audio(payload):
    """
    {
      "prompt": "æ­Œè¯",
      "tags": "pop metal male melancholic",
      "title": "æ­Œå",
      "make_instrumental": False,
      "wait_audio": False,
    }

    :param payload:
    :return:
    """
    url = f"{base_url}/api/custom_generate"
    response = httpx.post(url, json=payload)
    return response.json()


def generate_audio_by_prompt(payload):
    """
    {
        "prompt": "A popular heavy metal song about war, sung by a deep-voiced male singer, slowly and melodiously. The lyrics depict the sorrow of people after the war.",
        "make_instrumental": False,
        "wait_audio": False
    }
    :param payload:
    :return:
    """
    url = f"{base_url}/api/generate"
    response = httpx.post(url, json=payload)
    return response.json()


def get_audio_information(audio_ids):
    url = f"{base_url}/api/get?ids={audio_ids}"
    response = httpx.get(url)
    return response.json()


def get_quota_information():
    url = f"{base_url}/api/get_limit"
    response = httpx.get(url)
    return response.json()


def song_info(df):
    """
    #   'audio_url': 'https://cdn1.suno.ai/63c85335-d8ec-4e17-882a-e51c2f358b2d.mp3',
    #   'video_url': 'https://cdn1.suno.ai/25c7e34b-6986-4f7c-a5f2-537dd80e370c.mp4',
    # https://cdn1.suno.ai/image_bea09d9e-be4a-4c27-a0bf-67c4a92d6e16.png
    :param df:
    :return:
    """
    df['ğŸµéŸ³ä¹é“¾æ¥'] = df['id'].map(
        lambda x: f"**è¯·ä¸¤åˆ†é’Ÿåè¯•å¬**[ğŸ§éŸ³é¢‘](https://cdn1.suno.ai/{x}.mp3)[â–¶ï¸è§†é¢‘](https://cdn1.suno.ai/{x}.mp4)"
    )
    df['ä¸“è¾‘å›¾'] = df['id'].map(lambda x: f"![ğŸ–¼](https://cdn1.suno.ai/image_{x}.png)")

    df_ = df[["id", "created_at", "model_name", "ğŸµéŸ³ä¹é“¾æ¥", "ä¸“è¾‘å›¾"]]

    return f"""
ğŸµ **ã€Œ{df['title'][0]}ã€**

`é£æ ¼: {df['tags'][0]}`

```toml
{df['prompt'][0]}
```


{df_.to_markdown(index=False).replace('|:-', '|-').replace('-:|', '-|')}
    """


from meutils.pipe import *
from meutils.cache_utils import ttl_cache
from meutils.decorators.retry import retrying
from meutils.queues.smooth_queue import SmoothQueue

from meutils.notice.feishu import send_message

from openai.types.chat.chat_completion import ChatCompletion
from openai.types.chat.chat_completion_chunk import ChatCompletionChunk

from chatllm.llmchain.completions import openai_completions
from chatllm.schemas.openai_api_protocol import ChatCompletionRequest, UsageInfo
from chatllm.schemas.suno_types import SongRequest
from chatllm.schemas.openai_types import chat_completion, chat_completion_chunk as _chat_completion_chunk

from chatllm.utils.openai_utils import to_openai_completion_params, openai_response2sse

from langchain_community.chat_models import ChatOpenAI
from langchain.output_parsers import OutputFixingParser, PydanticOutputParser


class Completions(object):

    def __init__(self, api_key):
        self.httpx_aclient = httpx.AsyncClient(
            base_url=api_key,
            follow_redirects=True,
            timeout=30)

    async def acreate(self, request: ChatCompletionRequest):
        chat_completion_chunk = _chat_completion_chunk.model_copy(deep=True)

        async for content in self._acreate(request):
            chat_completion_chunk.choices[0].delta.content = content
            yield chat_completion_chunk

        # ç»“æŸæ ‡è¯†
        chat_completion_chunk.choices[0].delta.content = ""
        chat_completion_chunk.choices[0].finish_reason = "stop"
        yield chat_completion_chunk

    @retrying
    async def _acreate(self, request: ChatCompletionRequest):
        """
        Song Description ï¼š 200
        Lyricsï¼š1250
        Style of Musicï¼š120
        Titleï¼š80
        """

        prompt = request.messages[-1]["content"]
        send_message(prompt)
        if prompt.startswith(("ä½¿ç”¨å››åˆ°äº”ä¸ªå­—ç›´æ¥è¿”å›è¿™å¥è¯çš„ç®€è¦ä¸»é¢˜",
                              "ç®€è¦æ€»ç»“ä¸€ä¸‹å¯¹è¯å†…å®¹ï¼Œç”¨ä½œåç»­çš„ä¸Šä¸‹æ–‡æç¤º promptï¼Œæ§åˆ¶åœ¨ 200 å­—ä»¥å†…")):
            return

        if "make_instrumental" in prompt:
            yield "> Auto Mode âœ…ï¼šçº¯éŸ³ä¹æ¨¡å¼\n\n"
            payload = {
                "gpt_description_prompt": prompt,
                "mv": 'chirp-v3-5',
                "prompt": "",
                "make_instrumental": True
            }
            df = await self.generate_by_prompt(payload)

        elif len(prompt.strip()) < 100:
            yield "> Auto Mode âœ…: ç”Ÿæˆæ­Œè¯\n\n"
            payload = {
                "gpt_description_prompt": prompt,
                "mv": 'chirp-v3-5',
                "prompt": "",
                "make_instrumental": False
            }
            df = await self.generate_by_prompt(payload)

        else:

            song_request: SongRequest = self.prompt_parser(prompt)  # SongRequest
            payload = {
                "title": song_request.title,
                "tags": song_request.music_style,
                "prompt": song_request.lyrics,
                "continue_at": song_request.continue_at,
                "continue_clip_id": song_request.continue_clip_id,

                "mv": 'chirp-v3-5',

            }

            # title='My Song' lyrics='[Verse]...[Chorus]...[Bridge]...' music_style='Pop' continue_clip_id='8c7f666a-4df6-4657-8a83-d630b2b8ab56' continue_at=120
            # {
            #   "prompt": "string",
            #   "mv": "chirp-v3-0",
            #   "title": "string",
            #   "tags": "string",
            #   "continue_at": 120,
            #   "continue_clip_id": "string"
            # }
            send_message(str(payload))
            yield f"""```json\n{payload}\n```"""
            df = await self.custom_generate(payload)

        ids = ','.join(df['id'].tolist())  # df ä¸ºç©º

        yield f"""```\nTask ids: {ids}\n```\n\n"""
        yield f"""[éŸ³ä¹ä»»åŠ¡]("""

        for i in range(100):
            yield f"""{'ğŸµ' if i % 2 else 'ğŸ”¥'}"""
            await asyncio.sleep(1)

            if i > 10:  # 5ç§’åæ‰å¼€å§‹å›è°ƒ
                await asyncio.sleep(3)
                df = await self.get_information(ids)

                logger.debug("å›è°ƒæ­Œæ›²")

                if all(df.status == 'streaming'):  # æ­Œè¯ç”Ÿæˆ
                    yield f""") âœ…\n\n"""
                    _ = song_info(df)
                    yield _
                    send_message(_)
                    break
                elif all(df.status == 'error'):
                    yield f""") â\n\n"""
                    yield f"""âš ï¸è§¦å‘å†…å®¹å®¡æŸ¥ï¼Œè¯·ä¿®æ”¹åé‡è¯•"""
                    send_message(df.to_markdown())
                    break

    def create_sse(self, request: ChatCompletionRequest):
        return openai_response2sse(self.acreate(request), redirect_model=request.model)

    @retrying
    async def custom_generate(self, payload):
        response = await self.httpx_aclient.post("/generate", json=payload)
        return pd.DataFrame(response.json().get('clips'))

    @retrying(min_seconds=3)
    async def generate_by_prompt(self, payload):
        response = await self.httpx_aclient.post("/generate/description-mode", json=payload)
        # print(response.json())
        return pd.DataFrame(response.json().get('clips'))

    @retrying
    async def get_information(self, ids):
        response0 = await self.httpx_aclient.get(f"/feed/{ids.split(',')[0]}")
        response1 = await self.httpx_aclient.get(f"/feed/{ids.split(',')[1]}")

        clips = response0.json() + response1.json()

        return pd.DataFrame([{**clip, **clip['metadata']} for clip in clips])

    def prompt_parser(self, prompt):
        song_parser = OutputFixingParser.from_llm(
            parser=PydanticOutputParser(pydantic_object=SongRequest),
            llm=ChatOpenAI(temperature=0),
            max_retries=2,
        )
        result = song_parser.parse(completion=prompt)  # é”™è¯¯è¢«è‡ªåŠ¨ä¿®æ­£
        return result


if __name__ == '__main__':
    prompt = """
    åœ¨10så¤„

    ç»§ç»­åˆ›ä½œ

    "6e579766-08ec-4b47-8674-1ebd6f3a366a"

    "make_instrumental\": true"

    """
    prompt += """
        è¯·æ ¹æ®æˆ‘çš„è‡ªå®šä¹‰æ­Œè¯å’ŒéŸ³ä¹é£æ ¼æ¥åˆ›ä½œæ­Œæ›²ï¼š
        ä¸­æ–‡æ ‡é¢˜ï¼šé…’å…¥æ„è‚ 
        è‹±æ–‡æ ‡é¢˜ï¼šWine and Sorrows
        éŸ³ä¹é£æ ¼ï¼šçº¯éŸ³ä¹

        æ­Œè¯ç»“æ„ï¼š
        [Intro]
        ï¼ˆç‹¬å¥ï¼‰

        [Verse 1]
        æœˆå…‰æ´’åœ¨ç ´æ—§çš„ç¯±ç¬†ï¼Œ
        æç™½æå£¶ç‹¬è‡ªå½·å¾¨ã€‚
        é…’é¦™é£˜é€¸å…¥äº‘ç«¯ï¼Œ
        ç¬”ä¸‹æ˜¯è±ªè¿ˆçš„æƒ³è±¡ã€‚

        [Chorus]
        ä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ
        åƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚
        å¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ
        äººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚

        [Verse 2]
        æ±Ÿæ°´æµæ·Œå¸¦èµ°å¿§ä¼¤ï¼Œ
        æœç”«å‡çœ‰æ€å›½å®¶ã€‚
        æ–‡ç« é”‹åˆ©å‰‘å¦‚éœœï¼Œ
        å¿ƒä¸­è‹¦ï¼Œå´è¨€è€…æ— ç½ªå½“ã€‚

        [Chorus]
        ä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ
        åƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚
        å¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ
        äººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚

        [Bridge]
        ä¸€åƒå¹´æ¥è°èƒ½æ‡‚ï¼Œ
        é…’ä¸æ„æ˜¯æœ€æ·±çš„é‡ã€‚
        å†å²é•¿æ²³æ³¢æ¾œå£®ï¼Œ
        è¯—äººçœ¼ä¸­çœ‹å°½ç¹åç©ºã€‚

        [Chorus]
        ä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ
        åƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚
        å¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ
        äººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚

        [Outro]
        ï¼ˆç‹¬å¥ï¼‰

        éŸ³ä¹é£æ ¼ï¼š
        ä¼ ç»Ÿæ°‘è°£
        ä¸»è¦ä¹å™¨ï¼šå¤ç­ã€çµç¶ã€ç¬›å­
        èŠ‚å¥ï¼šç¼“æ…¢è€Œæ·±æƒ…
        æ°›å›´ï¼šæ²‰éƒã€å¤å…¸ã€å……æ»¡å†å²æ„Ÿ
    """
    print(Completions('http://154.3.0.117:39955').prompt_parser(prompt))

    # _ = arun(Completions('http://154.3.0.117:39955').generate_by_prompt({"gpt_description_prompt": "å†™é¦–æ­Œæ›²"}))
    # print(_)
    # payload = {
    #     "title": "Wine and Sorrows",
    #     "tags": "ä¼ ç»Ÿæ°‘è°£",
    #     "prompt": "[Intro]\nï¼ˆç‹¬å¥ï¼‰\n\n[Verse 1]\næœˆå…‰æ´’åœ¨ç ´æ—§çš„ç¯±ç¬†ï¼Œ\næç™½æå£¶ç‹¬è‡ªå½·å¾¨ã€‚\né…’é¦™é£˜é€¸å…¥äº‘ç«¯ï¼Œ\nç¬”ä¸‹æ˜¯è±ªè¿ˆçš„æƒ³è±¡ã€‚\n\n[Chorus]\nä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ\nåƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚\nå¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ\näººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚\n\n[Verse 2]\næ±Ÿæ°´æµæ·Œå¸¦èµ°å¿§ä¼¤ï¼Œ\næœç”«å‡çœ‰æ€å›½å®¶ã€‚\næ–‡ç« é”‹åˆ©å‰‘å¦‚éœœï¼Œ\nå¿ƒä¸­è‹¦ï¼Œå´è¨€è€…æ— ç½ªå½“ã€‚\n\n[Chorus]\nä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ\nåƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚\nå¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ\näººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚\n\n[Bridge]\nä¸€åƒå¹´æ¥è°èƒ½æ‡‚ï¼Œ\né…’ä¸æ„æ˜¯æœ€æ·±çš„é‡ã€‚\nå†å²é•¿æ²³æ³¢æ¾œå£®ï¼Œ\nè¯—äººçœ¼ä¸­çœ‹å°½ç¹åç©ºã€‚\n\n[Chorus]\nä¸€å£¶æµŠé…’å–œç›¸é€¢ï¼Œ\nåƒè½½å­¤æ„åªæœç”«æ‡‚ã€‚\nå¤é“è¥¿é£ç˜¦é©¬é—´ï¼Œ\näººé—´äº‹ï¼Œä¸¤è¡Œæ¸…æ³ªé•¿ã€‚\n\n[Outro]\nï¼ˆç‹¬å¥ï¼‰",
    #     "continue_at": 120,
    #     # "continue_clip_id": None,
    #     "mv": "chirp-v3-0"
    # }
    # _ = arun(Completions('http://154.3.0.117:39955').custom_generate(payload))
    # print(_)

#     data = generate_audio_by_prompt({
#         "prompt": "A popular heavy metal song about war, sung by a deep-voiced male singer, slowly and melodiously. The lyrics depict the sorrow of people after the war.",
#         "make_instrumental": False,
#         "wait_audio": False
#     })
#
#     # ids = f"{data[0]['id']},{data[1]['id']}"
#     # print(f"ids: {ids}")
#     #
#     # for _ in range(60):
#     #     data = get_audio_information(ids)
#     #     if data[0]["status"] == 'streaming':
#     #         print(f"{data[0]['id']} ==> {data[0]['audio_url']}")
#     #         print(f"{data[1]['id']} ==> {data[1]['audio_url']}")
#     #         break
#     #     # sleep 5s
#     #     time.sleep(5)
#
#     payload = {
#         "prompt": "æˆ‘ä¸æ˜¯æç™½" * 100,
#         "tags": "pop metal male melancholic",
#         "title": "æ­Œå",
#         # "make_instrumental": False,
#         # "wait_audio": False,
#     }
#
#     print(custom_generate_audio(payload))
# # {'error': 'Prompt, tags, and title are required'}
