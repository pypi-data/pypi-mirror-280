# coding=utf-8
import asyncio
from playwright.async_api import async_playwright
import requests
import json
import uuid
import re
import sys
import os
import random
from colorlog import ColoredFormatter
import logging
from os.path import abspath, dirname, join
from logging import handlers
from datetime import datetime
from datetime import datetime, timedelta, timezone
from playwright.sync_api import sync_playwright

tz_utc_8 = timezone(timedelta(hours=8))

link_re = r"\[(.*)\]\((https?://[^\)\s]+)\)"


# åˆ›å»ºUTC+8åŒ—äº¬æ—¶é—´çš„datetimeçš„æ ‡å‡†æ—¶é—´æ ¼å¼
def getNowDateTime():
    nowTime = datetime.now(tz=tz_utc_8).strftime("%Y-%m-%d %H:%M:%S")
    return nowTime


# æ–¹ä¾¿ç”ŸæˆLogseqå¯ä»¥è¯†åˆ«çš„æ—¥å¿—æ–‡ä»¶æ ¼å¼
def getNowDate():
    nowTime = datetime.now(tz=tz_utc_8).strftime("%Y_%m_%d")
    return nowTime


# æ–¹ä¾¿ç”ŸæˆObsidian-Memoså¯ä»¥è¯†åˆ«çš„èŠ‚ç‚¹æ ¼å¼
def getNowTime():
    nowTime = datetime.now(tz=tz_utc_8).strftime("%H:%M")
    return nowTime


# str -> datetime -> timeStamp
def getTimeStamp(dataTimeStr):
    d = datetime.strptime(dataTimeStr, "%Y-%m-%d %H:%M:%S")
    t = int(d.timestamp())
    return t


# timeStamp -> datetime -> str
def getDateTimeStr(timeStamp):
    # print("origin timeStamp: " + str(int(timeStamp)))
    lastTime = 1664092451
    d = datetime.fromtimestamp(timeStamp, tz=tz_utc_8)
    # print("datetime: " + str(d))
    # %Y-%m-%d %H:%M:%S.%f
    f = d.strftime("%Y-%m-%d %H:%M:%S")
    # print("dataTimeStr: " + f)
    return f


# æ‰“å°æ–‡ä»¶è·¯å¾„
def printPath(path):
    print(path)
    print(os.path.dirname(path), ".dir")
    print(os.path.basename(path), ".basename")
    print(os.path.splitext(path)[0], ".stem")
    print(os.path.splitext(path)[1], ".ext")
    print(os.path.splitext(os.path.basename(path))[0])


# è¿”å›å¸¦åç¼€åçš„æ–‡ä»¶å,eg:2022-06-15.md
def getFileExt(path):
    return os.path.basename(path)


# è¿”å›æ–‡ä»¶çš„åç¼€åï¼Œå¯èƒ½ä¸ºç©ºï¼Œeg:.md
def getFileExt(path):
    return os.path.splitext(path)[1]


# è¿”å›æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹ï¼Œeg:C:/Users/Administrator/Dropbox/MyGithub/MyPython/2022-06-15ä¸‹åˆ2_10_05å¯¼å‡ºè‘«èŠ¦ç¬”è®°æ•°æ®
def getFileDir(path):
    return os.path.dirname(path)


# è¿”å›æ— åç¼€åçš„æ–‡ä»¶åï¼Œeg:2022-06-15
def getFileName(path):
    return os.path.splitext(os.path.basename(path))[0]


# åœ¨åŒä¸€æ–‡ä»¶å¤¹ä¸‹çš„ä¸¤ä¸ªæ–‡ä»¶ï¼Œé‡å‘½å
def renameFileInDir(dir, src, dest):
    fileName = os.path.join(dir, src)
    newFileName = os.path.join(dir, dest)
    print(fileName, "->", newFileName)
    os.rename(fileName, newFileName)


# å¢é‡å†™å…¥
def writeStrAppend(val, path):
    file = open(path, "a", encoding="utf-8")
    file.write(val)
    file.flush()
    file.close()
    print(f"å¢é‡å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶æˆåŠŸï¼š{path}")


# åˆå¹¶æ–‡ä»¶
def mergeFile(src, dest):
    print("mergeFile", src, dest)
    s = readFile(src)
    tf = datetime.now().strftime("%Y_%m_%d-%H_%M_%S")
    content = f"\n\n## MergeFile-{tf}\n\n" + s
    writeStrAppend(content, dest)
    os.remove(src)


# éå†æ–‡ä»¶å¤¹
def traverseDir(dir):
    files = os.listdir(dir)
    for file in files:
        if not os.path.isdir(file):
            f = open(f"{dir}/{file}")
            name = os.path.splitext(os.path.basename(file))[0]
            print(name)


# éå†æ–‡ä»¶ï¼Œä¸€è¡Œè¡Œéå†ï¼Œè¯»å–æ–‡æœ¬
def readFileWithLines(file):
    str = ""
    iter_f = iter(file)
    for line in iter_f:
        str = str + line
    return str


# è¯»å–æ–‡ä»¶
def readFile(path):
    str = ""
    with open(path, "r", encoding="utf-8") as f:
        str = f.read()
    print(f"è¯»å–æ–‡ä»¶æˆåŠŸï¼š{path}")
    return str


# è¯»å–jsonåˆ°map
def read_map(path):
    json_str = readFile(path)
    return json.loads(json_str)


# éå†æ–‡ä»¶å¤¹,å¯¹æ¯ä¸ªæ–‡ä»¶éƒ½åšä¸€ç§æ“ä½œ
def traverseDirWithProcess(dir, process):
    files = os.listdir(dir)
    if len(files) == 0:
        print("æ²¡æœ‰éœ€è¦æ“ä½œçš„æ–‡ä»¶", dir)
        return
    for file in files:
        if not os.path.isdir(file):
            # f = f"{dir}/{file}"
            f = os.path.join(dir, file)
            process(f)


# å†™å…¥mapåˆ°æ–‡ä»¶,æŒ‰jsonæ ¼å¼ä¿å­˜
def writeMap(val, path):
    file = open(path, "w", encoding="utf-8")
    json_str = json.dumps(val, indent=4, ensure_ascii=False, separators=(",", ":"))
    file.write(json_str)
    file.flush()
    file.close()
    print(f"å†™å…¥mapåˆ°æ–‡ä»¶æˆåŠŸï¼š{path}")


# å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶
def writeStr(val, path):  # å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶
    if os.path.exists(path):
        os.remove(path)
    with open(path, "w", encoding="utf-8") as file:
        file.write(val)
        print(f"å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶æˆåŠŸï¼š{path}")


# å¢é‡å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶
def writeStrAppend(val, path):
    file = open(path, "a", encoding="utf-8")
    file.write(val)
    file.flush()
    file.close()
    print(f"å¢é‡å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶æˆåŠŸï¼š{path}")


# å¢é‡å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶-åœ¨å¤´éƒ¨æ·»åŠ 
def writeStrAppendHead(val, path):
    src = ""
    if os.path.exists(path):
        src = read_file(path)
    file = open(path, "w")
    content = val + "\n" + src
    file.write(content)
    file.flush()
    file.close()
    print(f"å¢é‡å†™å…¥æ–‡æœ¬åˆ°æ–‡ä»¶å¤´éƒ¨æˆåŠŸï¼š{path}")


# å†™å…¥åˆ—è¡¨åˆ°æ–‡ä»¶
def writeList(val, path):
    file = open(path, "w")
    file.write("\n".join(val))
    file.flush()
    file.close()
    print(f"å†™å…¥åˆ—è¡¨åˆ°æ–‡ä»¶æˆåŠŸï¼š{path}")


# è¿‡æ»¤æ‰Macç³»ç»Ÿé»˜è®¤çš„.DS_Storeæ–‡ä»¶
def isnotDsStore(val):
    if not re.match("^.*[.]DS_Store$", val):
        return True
    else:
        return False


def traverseFolder(dirPath, process):
    # è·å–ç›®å½•åˆ—è¡¨
    listDir = os.listdir(dirPath)
    # éå†ç›®å½•åˆ—è¡¨
    for path in listDir:
        fullPath = os.path.join(dirPath, path)
        # æ˜¯æ–‡ä»¶å¤¹çš„è¯ï¼Œå°±å…ˆæ‰“å°æ–‡ä»¶å¤¹çš„åç§°ï¼Œå†å»éå†è¿™ä¸ªå­æ–‡ä»¶å¤¹
        if os.path.isdir(fullPath):
            # print(fullPath)
            traverseFolder(fullPath, process)
        # æ˜¯æ–‡ä»¶çš„è¯ï¼Œç›´æ¥å¤„ç†å°±å¥½äº†
        else:
            process(fullPath)


def delete(path):
    end = path[-7:]
    # print(path)
    li = ["(1).pdf", "(2).pdf", "(1).mp3", "(2).mp3"]
    if end in li:
        # os.remove(path)
        print(path)


# import traceback


# æ‰“å°å‡½æ•°Frame MyLogUtil.py:167 f1()
def formatFrameStr(frame):
    funcName = frame.f_code.co_name
    filePath = frame.f_code.co_filename
    fileName = os.path.basename(filePath)
    fileLineno = frame.f_lineno
    return f"{fileName}:{fileLineno} {funcName}()"


# æ‰“å°è¢«è£…é¥°çš„å‡½æ•°Frame MyLogUtil.py:167 f1()->f2()
def formatAnnoFrameStr(frame):
    funcName = frame.f_code.co_name
    filePath = frame.f_code.co_filename
    fileName = os.path.basename(filePath)
    fileLineno = frame.f_lineno
    return f"{fileName}:{fileLineno} {funcName}()"


# æ‰“å°æ‰€æœ‰å‡½æ•°Frame depth=å›æº¯æ·±åº¦ï¼Œæ— åˆ™å›æº¯åˆ°æœ€åº•å±‚
def getFrames(depth=float("inf")):
    # print(f"depth: {depth}")
    trace = sys._getframe(0)
    str = formatFrameStr(trace)
    printDepth = 0
    while trace.f_back and printDepth <= depth:
        str = formatFrameStr(trace.f_back)
        # logger.debug(f"{printDepth} {str}")
        trace = trace.f_back
        printDepth = printDepth + 1
        # print(f"{printDepth} < {depth}")
    return str


# è·å–å¯¹è±¡
def get_logger():
    # é…ç½®è¾“å‡ºè·¯å¾„ /Users/yutianran/Documents/MyPKM/log/LogUtil_2022_06_15.log
    projectDir = dirname(abspath(__file__))
    logDir = projectDir + "/log"
    date = getNowDate()
    logPath = join(logDir, f"LogUtil_{date}.log")
    debugLogPath = join(logDir, f"DebugLog_{date}.log")
    infoLogPath = join(logDir, f"InfoLog_{date}.log")
    errorLogPath = join(logDir, f"ErrorLog_{date}.log")
    # [å¸¸è§æ—¥å¿—å‚æ•°](https://www.cnblogs.com/nancyzhu/p/8551506.html ) %(funcName)s %(filename)s:%(lineno)d
    logformat = "[%(levelname)-1.1s] %(asctime)s | %(message)s"
    # colorLogformat = "%(log_color)s[%(levelname)1.1s] %(asctime)s | %(message)s"
    LOG_LEVEL = logging.DEBUG
    logging.root.setLevel(LOG_LEVEL)
    # è®¾ç½®æ§åˆ¶å°è¾“å‡º
    streamHandler = logging.StreamHandler()
    streamHandler.setLevel(LOG_LEVEL)
    streamHandler.setFormatter(
        logging.Formatter(logformat, datefmt="%Y-%m-%d %H:%M:%S")
    )

    # åˆ›å»ºä¸åŒçº§åˆ«çš„æ–‡ä»¶å¤„ç†å™¨
    # intervalæ˜¯æ—¶é—´é—´éš”ï¼ŒbackupCountæ˜¯å¤‡ä»½æ–‡ä»¶çš„ä¸ªæ•°ï¼Œå¦‚æœè¶…è¿‡è¿™ä¸ªä¸ªæ•°ï¼Œå°±ä¼šè‡ªåŠ¨åˆ é™¤ï¼Œ
    # whenæ˜¯é—´éš”çš„æ—¶é—´å•ä½ï¼Œå•ä½æœ‰ä»¥ä¸‹å‡ ç§ï¼šS-ç§’ M-åˆ† H-å°æ—¶ D-å¤© W-æ¯æ˜ŸæœŸ interval==0æ—¶ä»£è¡¨æ˜ŸæœŸä¸€ midnight-æ¯å¤©å‡Œæ™¨
    debugFileHandler = handlers.TimedRotatingFileHandler(
        filename=join(logDir, f"LogUtil_{date}_debug.log"),
        when="D",
        backupCount=5,
        encoding="utf-8",
    )
    debugFileHandler.setLevel(logging.DEBUG)
    debugFileHandler.setFormatter(
        logging.Formatter(logformat, datefmt="%Y-%m-%d %H:%M:%S")
    )

    infoFileHandler = handlers.TimedRotatingFileHandler(
        filename=join(logDir, f"LogUtil_{date}_info.log"),
        when="D",
        backupCount=5,
        encoding="utf-8",
    )
    infoFileHandler.setLevel(logging.INFO)
    infoFileHandler.setFormatter(
        logging.Formatter(logformat, datefmt="%Y-%m-%d %H:%M:%S")
    )

    errorFileHandler = handlers.TimedRotatingFileHandler(
        filename=join(logDir, f"LogUtil_{date}_error.log"),
        when="D",
        backupCount=5,
        encoding="utf-8",
    )
    errorFileHandler.setLevel(logging.ERROR)
    errorFileHandler.setFormatter(
        logging.Formatter(logformat, datefmt="%Y-%m-%d %H:%M:%S")
    )

    # æœ€ç»ˆåˆ›å»ºçš„Loggerå¯¹è±¡
    logger = logging.getLogger(logPath)
    logger.setLevel(LOG_LEVEL)
    logger.addHandler(debugFileHandler)
    logger.addHandler(infoFileHandler)
    logger.addHandler(errorFileHandler)
    logger.addHandler(streamHandler)
    return logger


logger = get_logger()


# ç»™msgåŠ ä¸Šæ–‡ä»¶åå’Œè¡Œå·çš„è£…é¥°å™¨
def formartMsg(msg, depth=0):
    # ä¸º-1æ—¶å°±ä¸åŠ å‰ç¼€äº†
    if depth == -1:
        return msg
    prefix = getFrames(depth)
    msg = f"{prefix} | {msg}"
    return msg


# é»˜ç„¶æ—¥å¿—æ–¹æ³•ï¼Œæ–¹ä¾¿æ›¿æ¢çº§åˆ«
def log(msg, depth=2):
    logger.info(formartMsg(msg, depth))


# ç”¨è£…é¥°å™¨ï¼Œä¿®æ”¹msgä¸ºformatMsg
def msgWrapper(func):
    def wrapper(*args, **kwargs):
        msg = args[0]
        foarmatMsg = formartMsg(msg, 2)
        # print(f"msg: {msg}")
        # print(f"foarmatMsg: {foarmatMsg}")
        func(foarmatMsg, **kwargs)

    return wrapper


# å°è£…å‡ ä¸ªç®€å•çš„æ–¹æ³•ï¼Œä»¥ä¾›å¤–ç•Œè°ƒç”¨
# è°ƒè¯•ä¿¡æ¯
# ä¸»è¦æœ‰è£…é¥°å™¨è‡ªåŠ¨æ·»åŠ çš„å‚æ•°æ‰“å°
def debug(msg, depth=2):
    logger.debug(formartMsg(msg, depth))


# æ—¥å¸¸å¼€å‘ä¿¡æ¯-é»˜è®¤
@msgWrapper
def info(msg):
    logger.info(msg)


# é‡è¦è­¦å‘Šä¿¡æ¯
@msgWrapper
def warning(msg):
    logger.warning(msg)


# é”™è¯¯ä¿¡æ¯
@msgWrapper
def error(msg):
    logger.error(msg)


@msgWrapper
def critical(msg):
    logger.critical(msg)


# æ›¿æ¢å¸¸ç”¨çš„printä¸ºLogUtil
print = debug
printf = debug


def test_log():
    debug("This is debug.")
    info("This is info.")
    warning("This is warning.")
    error("This is error.")
    critical("This is critical.")
    log("This is log.")


def read_file(filename):
    try:
        with open(filename, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        print(f"Error: The file '{filename}' does not exist.")
    except Exception as e:
        print(f"An error occurred: {e}")


# æ­£åˆ™è¡¨è¾¾å¼ç”¨äºæŸ¥æ‰¾æ–‡ä»¶ä¸­æ²¡æœ‰httpçš„è¡Œ
def find_lines_without_regex(content):
    lines = content.split("\n")
    for i, line in enumerate(lines):
        if not re.search(link_re, line):
            print(f"Line {i+1}: {line.strip()}")


# æ­£åˆ™è¡¨è¾¾å¼ç”¨äºæŸ¥æ‰¾Markdownä¸­çš„é“¾æ¥
def find_md_links(md_content):
    links = re.findall(link_re, md_content)
    return links


def save_url(url):
    api = "https://api-prod.omnivore.app/api/graphql"
    url_uuid = uuid.uuid5(uuid.NAMESPACE_URL, url)
    payload = json.dumps(
        {
            "query": "mutation SaveUrl($input: SaveUrlInput!) { saveUrl(input: $input) { ... on SaveSuccess { url clientRequestId } ... on SaveError { errorCodes message } } }",
            "variables": {
                "input": {
                    "clientRequestId": str(url_uuid),
                    "source": "api",
                    "url": url,
                }
            },
        }
    )
    headers = {
        "authorization": "5453e79e-0b85-44e2-9827-fb5476ab1c7c",
        "User-Agent": "Apifox/1.0.0 (https://apifox.com)",
        "content-type": "application/json",
        "Accept": "*/*",
        "Host": "api-prod.omnivore.app",
        "Connection": "keep-alive",
    }
    response = requests.request("POST", api, headers=headers, data=payload)
    print(response.status_code, response.text)


def get_real_url(url):
    random_ip = random.choice(ips)
    ip = random_ip.get("ip")
    port = random_ip.get("port")
    print(f"url: {url} random_ip: {ip}:{port}")
    # åˆå§‹åŒ–Playwright
    with sync_playwright() as playwright:
        # åœ¨Chromiumæµè§ˆå™¨ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡
        # browser = playwright.chromium.launch()
        browser = playwright.chromium.launch(
            #    proxy={"server": f"http://{ip}:{port}"}
            proxy={"server": f"http://127.0.0.1:7890"}
        )
        context = browser.new_context()

        # åˆ›å»ºä¸€ä¸ªæ–°çš„é¡µé¢å¹¶æ‰“å¼€æœ¬åœ°HTMLæ–‡ä»¶
        page = context.new_page()
        page.goto(url)

        # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        page.wait_for_load_state()

        # è·å–é¡µé¢æ ‡é¢˜
        title = page.title()
        print(f"title: {title} url: {url}")

        # æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆè¦æ±‚çš„å…ƒç´ 
        # elements = page.query_selector_all(".fav-list-container li.fav-item a")
        # # è·å–å…ƒç´ çš„æ–‡æœ¬æ•°æ®
        # text_data = [element.text_content() for element in elements]

        # å…³é—­æµè§ˆå™¨ä¸Šä¸‹æ–‡
        context.close()
        browser.close()
        return title


async def get_real_url_async(url):
    async with async_playwright() as playwright:
        browser = await playwright.chromium.launch()
        context = await browser.new_context()

        page = await context.new_page()
        await page.goto(url)
        await page.wait_for_load_state()

        title = await page.title()
        print(title, url)

        await context.close()
        await browser.close()
        return title


import asyncio


def async_test():
    # å‡è®¾urlsæ˜¯åŒ…å«100ä¸ªé“¾æ¥çš„åˆ—è¡¨
    urls = [...]

    async def fetch_all_urls():
        tasks = [get_real_url_async(url) for url in urls]
        return await asyncio.gather(*tasks)

    asyncio.run(fetch_all_urls())


def is_valid_url(url):
    try:
        response = requests.head(url)  # å‘é€HEADè¯·æ±‚ä»¥è·å–å“åº”å¤´è€Œä¸æ˜¯æ•´ä¸ªé¡µé¢å†…å®¹
        print(response.status_code, url)
        return response.status_code != 404
    except requests.RequestException:
        return False


invalid_titles = ["ä½ ä¼¼ä¹æ¥åˆ°äº†æ²¡æœ‰çŸ¥è¯†å­˜åœ¨çš„è’åŸ - çŸ¥ä¹"]


def print_links(links):
    for i, (title, url) in enumerate(links):
        print(f"index:{i} title:{title} url:{url}")


def save_links(links):
    for i, (title, url) in enumerate(links):
        # å…ˆæ£€æµ‹urlæ˜¯å¦æœ‰æ•ˆ
        title = get_real_url(url)
        if title in invalid_titles:
            print(f"invalid_titles index:{i} title:{title} url:{url}")
        else:
            print(f"index:{i} title:{title} url:{url}")


if __name__ == "__main__":
    # print(getNowDateTime())
    # print(getNowDate())
    # print(getNowTime())
    # print(getTimeStamp(getNowDateTime()))
    # print(getDateTimeStr(datetime.now(tz=tz_utc_8).timestamp()))
    # file_path = "/Users/yutianran/Documents/MyPKM/MyNote/EzWorkflowy/ğŸ—‚ï¸Categoryä¹¦ç­¾/AndroidæŠ€æœ¯æ¢ç´¢ - çŸ¥ä¹.md"
    # md_content = read_file(file_path)
    # find_lines_without_regex(md_content)
    # links = find_md_links(md_content)[:2]
    # save_links(links)

    # print_links(links)
    # test_log()
    # async def fetch_all_urls():
    #     tasks = [get_real_url_async(url) for i, (title, url) in enumerate(links)]
    #     return await asyncio.gather(*tasks)

    # asyncio.run(fetch_all_urls())
    ips_content = read_file("assets/ips.json")
    ips = json.loads(ips_content).get("obj")
    print("ipsä»£ç†æ•°é‡: " + str(len(ips)))
