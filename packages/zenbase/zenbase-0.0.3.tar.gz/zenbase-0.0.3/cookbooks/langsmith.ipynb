{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1377617ec4c1781f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:42.834100Z",
     "start_time": "2024-06-07T21:34:42.824051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv(Path(\"../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808bae4c98be5c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:43.397025Z",
     "start_time": "2024-06-07T21:34:43.394067Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c49d5afd7ed94163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:45.597153Z",
     "start_time": "2024-06-07T21:34:45.183731Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from zenbase.types import LMRequest, deflm\n",
    "from langsmith import traceable\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = wrap_openai(OpenAI())\n",
    "\n",
    "# Define your LLM function\n",
    "@traceable\n",
    "def openai_json_response(inputs: dict) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": json.dumps(inputs)}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# Define your Langsmith evaluator\n",
    "def score_answer(run: Run, example: Example):\n",
    "    output = str(run.outputs[\"answer\"])\n",
    "    target = example.outputs[\"answer\"].split(\"#### \")[-1]\n",
    "    return {\n",
    "        \"key\": \"correctness\",\n",
    "        \"score\": int(output == target),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "269ce9c328f8e5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:50.592052Z",
     "start_time": "2024-06-07T21:34:46.755696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'yellow-part-12' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=17db3be3-eaeb-4545-be1a-a16789d96d45\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0f6bd4d4704252a5deef5c19bc442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ExperimentResults yellow-part-12>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using LangSmith\n",
    "from langsmith import Client, evaluate\n",
    "\n",
    "langsmith = Client()\n",
    "evalset = list(langsmith.list_examples(dataset_name=\"gsm8k-test-examples\"))\n",
    "\n",
    "evaluate_kwargs = dict(\n",
    "    data=evalset,\n",
    "    evaluators=[score_answer],\n",
    "    client=langsmith,\n",
    "    max_concurrency=2,\n",
    ")\n",
    "\n",
    "evaluate(openai_json_response, **evaluate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9592f3913f694364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:09.830906Z",
     "start_time": "2024-06-07T21:35:09.824879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap your existing chain with @deflm and take in a `LMRequest` object\n",
    "# An LMRequest has the inputs for your chain and has a `zenbase` attribute.\n",
    "# This `zenbase` attribute includes the fields that Zenbase optimises.\n",
    "@deflm\n",
    "@traceable\n",
    "def openai_json_response(request: LMRequest) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            {\"role\": \"user\", \"content\": json.dumps(demo.inputs)},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(demo.outputs)},\n",
    "        ]\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(request.inputs)})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c996174108b0981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:37.205056Z",
     "start_time": "2024-06-07T21:35:22.266388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-multi-lateral-composite-open-system-f8e07e82' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=41a222d1-fc2c-4ee5-85fb-892a707ae0e0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae48ee9e95084039b5ae4a7a39942c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-enterprise-wide-system-worthy-archive-fb7fa631' at:\n",
      "https://smith.langchain.com/o/b0308fb6-cdef-5df3-affa-b8dba287e3ed/datasets/1b7abb1a-8922-4eba-b0b6-b617241d8794/compare?selectedSessions=02baafbd-5c56-4ed8-8963-8c5a02a74df6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b9ce65ade94dbe9b8229299dcc15c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zenbase.helpers.langchain import ZenLangSmith\n",
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "\n",
    "demoset = ZenLangSmith.examples_to_demos(\n",
    "    langsmith.list_examples(dataset_name=\"gsm8k-golden-demos\")\n",
    ")\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n",
    "\n",
    "best_fn, candidates = optimizer.perform(\n",
    "    # Pass deflm decorated function\n",
    "    openai_json_response,\n",
    "    # Exactly the same as what you are passing to your evaluate function\n",
    "    evaluator=ZenLangSmith.metric_evaluator(**evaluate_kwargs),\n",
    "    samples=2,\n",
    "    rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da6e5476084d83fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:41.601645Z",
     "start_time": "2024-06-07T21:35:39.374294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'I have 30% + Mo has 24.5% = 54.5% combined shares assigned.\\nThis means there are 100% - 54.5% = 45.5% unassigned shares.\\nThus, there are 45.5% of 10M shares unassigned, which is 10,000,000 * 45.5 / 100 = <<10000000*45.5/100>>4550000 shares unassigned.\\n#### 4550000'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can use your zenbase fn\n",
    "best_fn({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "280bbbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LMDemo(inputs={'question': 'James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?'}, outputs={'answer': 'He writes each friend 3*2=<<3*2=6>>6 pages a week\\nSo he writes 6*2=<<6*2=12>>12 pages every week\\nThat means he writes 12*52=<<12*52=624>>624 pages a year\\n#### 624'}),\n",
       " LMDemo(inputs={'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'}, outputs={'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}),\n",
       " LMDemo(inputs={'question': 'Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?'}, outputs={'answer': \"In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\\nBetty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\\nThis means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\\n#### 5\"}))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fn.zenbase.task_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "622d32eb538487a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:35:46.575798Z",
     "start_time": "2024-06-07T21:35:46.116757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '4'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "openai_json_response.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "openai_json_response({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00806fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aa9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
