{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "from celerite import plot_setup\n",
    "plot_setup.setup(auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kplr\n",
    "import copy\n",
    "import pickle\n",
    "import corner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from celerite.plot_setup import setup, get_figsize, COLORS\n",
    "\n",
    "import celerite\n",
    "from celerite import terms\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import emcee3\n",
    "from emcee3 import autocorr\n",
    "\n",
    "from astropy.stats import LombScargle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsteroTerm(terms.Term):\n",
    "\n",
    "    parameter_names = (\n",
    "        \"log_S_g\", \"log_omega_g\", \"log_nu_max\", \"log_delta_nu\",\n",
    "        \"epsilon\", \"log_A\", \"log_Q\", \"log_W\",\n",
    "    )\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.nterms = int(kwargs.pop(\"nterms\", 2))\n",
    "        super(AsteroTerm, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def get_complex_coefficients(self, params):\n",
    "        (log_S_g, log_omega_g, log_nu_max, log_delta_nu,\n",
    "         epsilon, log_A, log_Q, log_W) = params\n",
    "        alpha = np.exp(log_S_g + log_omega_g) / np.sqrt(2.0)\n",
    "        beta = np.exp(log_omega_g) / np.sqrt(2.0)\n",
    "        Q = 0.5 + np.exp(log_Q)\n",
    "        j = np.arange(-self.nterms, self.nterms+1, 1)\n",
    "        delta = j*np.exp(log_delta_nu) + epsilon\n",
    "        omega = 2*np.pi * (np.exp(log_nu_max) + delta)\n",
    "        S = np.exp(log_A - 0.5*delta**2*np.exp(2*log_W)) / Q**2\n",
    "        return (\n",
    "            np.append(alpha, S*omega*Q),\n",
    "            np.append(alpha, S*omega*Q/np.sqrt(4*Q*Q-1)),\n",
    "            np.append(beta, 0.5*omega/Q),\n",
    "            np.append(beta, 0.5*omega/Q*np.sqrt(4*Q*Q-1)),\n",
    "        )\n",
    "\n",
    "    def get_envelope(self, omega):\n",
    "        delta = omega/(2*np.pi) - np.exp(self.log_nu_max)\n",
    "        return np.sqrt(2/np.pi)*np.exp(self.log_A -\n",
    "                                       0.5*delta**2*np.exp(2*self.log_W))\n",
    "\n",
    "    def get_terms(self):\n",
    "        coeffs = self.get_complex_coefficients()\n",
    "        return [terms.ComplexTerm(*(np.log(args))) for args in zip(*coeffs)]\n",
    "\n",
    "    def get_freqs(self):\n",
    "        j = np.arange(-self.nterms, self.nterms+1, 1)\n",
    "        delta = j*np.exp(self.log_delta_nu) + self.epsilon\n",
    "        return np.exp(self.log_nu_max) + delta\n",
    "\n",
    "    def log_prior(self):\n",
    "        lp = super(AsteroTerm, self).log_prior()\n",
    "        if not np.isfinite(lp):\n",
    "            return lp\n",
    "        return lp - 0.5 * self.epsilon**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor to convert between day^-1 and uHz\n",
    "uHz_conv = 1e-6 * 24 * 60 * 60\n",
    "\n",
    "# Download the data for a giant star from MAST\n",
    "kicid = 11615890\n",
    "client = kplr.API()\n",
    "star = client.star(kicid)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "yerr = []\n",
    "\n",
    "for lc in star.get_light_curves():\n",
    "    data = lc.read()\n",
    "    x0 = data[\"TIME\"]\n",
    "    y0 = data[\"PDCSAP_FLUX\"]\n",
    "    m = (data[\"SAP_QUALITY\"] == 0) & np.isfinite(x0) & np.isfinite(y0)\n",
    "    x.append(x0[m])\n",
    "    mu = np.median(y0[m])\n",
    "    y.append((y0[m] / mu - 1.0) * 1e6)\n",
    "    yerr.append(1e6 * data[\"PDCSAP_FLUX_ERR\"][m] / mu)\n",
    "\n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "yerr = np.concatenate(yerr)\n",
    "\n",
    "inds = np.argsort(x)\n",
    "x = np.ascontiguousarray(x[inds], dtype=float)\n",
    "y = np.ascontiguousarray(y[inds], dtype=float)\n",
    "yerr = np.ascontiguousarray(yerr[inds], dtype=float)\n",
    "\n",
    "# Plot the light curve.\n",
    "fig, ax = plt.subplots(1, 1, figsize=get_figsize())\n",
    "ax.plot(x, y, \"k\", rasterized=True)\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(np.std(y) * np.array([-5.0, 5.0]))\n",
    "ax.set_xlabel(\"time [KBJD]\")\n",
    "ax.set_ylabel(\"relative flux [ppm]\")\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a frequency grid for the periodogram\n",
    "freq_uHz = np.linspace(1, 300, 100000)\n",
    "freq = freq_uHz * uHz_conv\n",
    "\n",
    "# Compute the periodogram on the full dataset\n",
    "model = LombScargle(x, y)\n",
    "power_all = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "power_all *= uHz_conv / len(x)  # Convert to ppm^2/uHz\n",
    "\n",
    "# Select a subset of the data\n",
    "np.random.seed(1234)\n",
    "n = int(30 * 48)\n",
    "n0 = np.random.randint(len(x)-n-1)\n",
    "fit_x, fit_y, fit_yerr = x[n0:n0+n], y[n0:n0+n], yerr[n0:n0+n]\n",
    "print(\"Range in subset of data: {0:.1f} days\".format(fit_x.max()-fit_x.min()))\n",
    "print(\"Fraction of full dataset: {0:.1f}%\".format(100 * n / len(x)))\n",
    "\n",
    "# Compute the periodogram on the subset\n",
    "model = LombScargle(fit_x, fit_y)\n",
    "power_some = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "power_some *= uHz_conv / len(fit_x)  # Convert to ppm^2/uHz\n",
    "\n",
    "# Remove background from periodograms\n",
    "def estimate_background(x, y, log_width=0.005):\n",
    "    count = np.zeros(len(x), dtype=int)\n",
    "    bkg = np.zeros_like(x)\n",
    "    x0 = np.log10(x[0])\n",
    "    while x0 < np.log10(x[-1]):\n",
    "        m = np.abs(np.log10(x) - x0) < log_width\n",
    "        bkg[m] += np.median(y[m])\n",
    "        count[m] += 1\n",
    "        x0 += 0.5 * log_width\n",
    "    return bkg / count\n",
    "bkg_all = estimate_background(freq_uHz, power_all)\n",
    "bkg_some = estimate_background(freq_uHz, power_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute $\\nu_\\mathrm{max}$ and $\\Delta \\nu$ from the full dataset\n",
    "for name, ps in zip((\"subset of data\", \"all data\"),\n",
    "                    (power_some-bkg_some, power_all-bkg_all)):\n",
    "    # Compute the smoothed power spectrum\n",
    "    df = freq_uHz[1] - freq_uHz[0]\n",
    "    smoothed_ps = gaussian_filter(ps, 10 / df)\n",
    "\n",
    "    # And the autocorrelation function of a lightly smoothed power spectrum\n",
    "    acor_func = autocorr.function(gaussian_filter(ps, 0.5 / df))\n",
    "    lags = df*np.arange(len(acor_func))\n",
    "    acor_func = acor_func[lags < 30]\n",
    "    lags = lags[lags < 30]\n",
    "\n",
    "    # Find the peaks\n",
    "    def find_peaks(z):\n",
    "        peak_inds = (z[1:-1] > z[:-2]) * (z[1:-1] > z[2:])\n",
    "        peak_inds = np.arange(1, len(z)-1)[peak_inds]\n",
    "        peak_inds = peak_inds[np.argsort(z[peak_inds])][::-1]\n",
    "        return peak_inds\n",
    "\n",
    "    peak_freqs = freq_uHz[find_peaks(smoothed_ps)]\n",
    "    nu_max = peak_freqs[peak_freqs > 5][0]\n",
    "\n",
    "    # Expected delta_nu: Stello et al (2009)\n",
    "    dnu_expected = 0.263 * nu_max ** 0.772\n",
    "    peak_lags = lags[find_peaks(acor_func)]\n",
    "    delta_nu = peak_lags[np.argmin(np.abs(peak_lags - dnu_expected))]\n",
    "    print(\"{0}: nu_max = {1}, delta_nu = {2}\".format(name, nu_max, delta_nu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter bounds\n",
    "bounds = dict((n, (-15, 15)) for n in AsteroTerm.parameter_names)\n",
    "bounds[\"log_nu_max\"] = np.log(np.array([130.0, 190.0])*uHz_conv)\n",
    "bounds[\"log_delta_nu\"] = np.log(np.array([12.5, 13.5])*uHz_conv)\n",
    "bounds[\"log_W\"] = (-3, 3)\n",
    "\n",
    "# Set up the GP model\n",
    "kernel = AsteroTerm(\n",
    "    log_S_g=np.log(np.var(y)),\n",
    "    log_omega_g=2.0,\n",
    "    log_nu_max=np.log(nu_max*uHz_conv),\n",
    "    log_delta_nu=np.log(delta_nu*uHz_conv),\n",
    "    epsilon=0.0,\n",
    "    log_A=np.log(np.var(y)),\n",
    "    log_Q=5.0,\n",
    "    log_W=-1.0,\n",
    "    bounds=bounds,\n",
    "    nterms=2,\n",
    ")\n",
    "kernel += terms.JitterTerm(\n",
    "    log_sigma=np.log(np.median(np.abs(np.diff(fit_y)))),\n",
    "    bounds=[(-15, 15)]\n",
    ")\n",
    "gp = celerite.GP(kernel)\n",
    "gp.compute(fit_x, fit_yerr)\n",
    "print(\"Initial log-likelihood: {0}\".format(gp.log_likelihood(fit_y)))\n",
    "print(gp.get_parameter_dict(include_frozen=True))\n",
    "\n",
    "# The objective function for optimization\n",
    "def nll(params):\n",
    "    gp.set_parameter_vector(params)\n",
    "    ll = gp.log_likelihood(fit_y, quiet=True)\n",
    "    if not np.isfinite(ll):\n",
    "        return 1e10\n",
    "    return -ll\n",
    "\n",
    "def grad_nll(params):\n",
    "    gp.set_parameter_vector(params)\n",
    "    return -gp.grad_log_likelihood(fit_y)[1]\n",
    "\n",
    "# Grid initialize\n",
    "print(\"Running a grid of optimizations...\")\n",
    "gp.kernel.thaw_all_parameters()\n",
    "initial = np.array(gp.get_parameter_vector())\n",
    "\n",
    "def get_ml_params(log_nu_max):\n",
    "    gp.set_parameter_vector(initial)\n",
    "    gp.kernel.set_parameter(\"terms[0]:log_nu_max\", log_nu_max)\n",
    "    gp.kernel.set_parameter(\n",
    "        \"terms[0]:log_delta_nu\",\n",
    "        np.log(0.263 * (np.exp(log_nu_max)/uHz_conv) ** 0.772 * uHz_conv)\n",
    "    )\n",
    "    p0 = gp.get_parameter_vector()\n",
    "    bounds = gp.get_parameter_bounds()\n",
    "    r = minimize(nll, p0, method=\"L-BFGS-B\", bounds=bounds)\n",
    "    gp.set_parameter_vector(r.x)\n",
    "    return r.fun, r.x\n",
    "\n",
    "with emcee3.pools.InterruptiblePool() as pool:\n",
    "    results = list(sorted(pool.map(\n",
    "        get_ml_params, gp.kernel.terms[0].log_nu_max + np.linspace(-0.05, 0.05, 5)\n",
    "    ), key=lambda o: o[0]))\n",
    "gp.set_parameter_vector(results[0][1])\n",
    "print(gp.get_parameter_dict(include_frozen=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use more modes in the MCMC:\n",
    "gp.kernel.terms[0].nterms = 3\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=get_figsize())\n",
    "ax.plot(freq_uHz, power_all, \"k\", alpha=0.8, rasterized=True)\n",
    "ax.plot(freq_uHz, gp.kernel.get_psd(2*np.pi*freq) * uHz_conv / (2*np.pi),\n",
    "        alpha=0.5, rasterized=True)\n",
    "ax.set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "ax.set_ylabel(\"power [$\\mathrm{ppm}^2\\,\\mu\\mathrm{Hz}^{-1}$]\")\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the probabilistic model for sampling\n",
    "def log_prob(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    lp = gp.log_prior()\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    ll = gp.log_likelihood(fit_y)\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    return ll + lp\n",
    "\n",
    "# Initialize and set bounds\n",
    "ndim, nwalkers = gp.vector_size, 32\n",
    "initial_samples = \\\n",
    "    gp.get_parameter_vector() + 1e-5 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "names = gp.get_parameter_names()\n",
    "ind_nu_max = names.index(\"kernel:terms[0]:log_nu_max\")\n",
    "ind_delta_nu = names.index(\"kernel:terms[0]:log_delta_nu\")\n",
    "\n",
    "# Save the current state of the GP and data\n",
    "with open(\"astero-{0}.pkl\".format(kicid), \"wb\") as f:\n",
    "    pickle.dump((\n",
    "        gp, fit_y, freq, power_all, power_some, len(x),\n",
    "    ), f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom proposal\n",
    "def astero_move(rng, x0):\n",
    "    x = np.array(x0)\n",
    "    f = 2.0 * (rng.rand(len(x)) < 0.5) - 1.0\n",
    "    x[:, ind_nu_max] = np.log(np.exp(x[:, ind_nu_max]) +\n",
    "                              f * np.exp(x[:, ind_delta_nu]))\n",
    "    return x, np.zeros(len(x))\n",
    "\n",
    "# The sampler will use a mixture of proposals\n",
    "sampler = emcee3.Sampler([\n",
    "    emcee3.moves.StretchMove(),\n",
    "    emcee3.moves.DEMove(1e-3),\n",
    "    emcee3.moves.KDEMove(),\n",
    "    emcee3.moves.MHMove(astero_move),\n",
    "], backend=emcee3.backends.HDFBackend(\"astero-{0}.h5\".format(kicid)))\n",
    "\n",
    "# Sample!\n",
    "with emcee3.pools.InterruptiblePool() as pool:\n",
    "    ensemble = emcee3.Ensemble(emcee3.SimpleModel(log_prob), initial_samples,\n",
    "                               pool=pool)\n",
    "    ensemble = sampler.run(ensemble, 20000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sampler.get_coords()\n",
    "plt.plot(c[:, :, ind_nu_max], alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.get_coords(discard=5000, flat=True)\n",
    "log_probs = sampler.get_log_probability(discard=5000, flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(gp.get_parameter_names())\n",
    "for i in range(len(names)):\n",
    "    name = names[i].split(\":\")[-1]\n",
    "    if name.startswith(\"log\"):\n",
    "        name = \"log(\"+name[4:]+\")\"\n",
    "    names[i] = name.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_var = np.median(gp._yerr**2)\n",
    "white_noise_all = measurement_var * uHz_conv / len(y)\n",
    "white_noise_some = measurement_var * uHz_conv / len(fit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model predictions\n",
    "time_grid = np.linspace(0, 1.4, 5000)\n",
    "n = 1000\n",
    "psds = np.empty((n, len(freq)))\n",
    "acors = np.empty((n, len(time_grid)))\n",
    "for i, j in enumerate(np.random.randint(len(samples), size=n)):\n",
    "    s = samples[j]\n",
    "    gp.set_parameter_vector(s)\n",
    "    psds[i] = gp.kernel.get_psd(2*np.pi*freq)\n",
    "    acors[i] = gp.kernel.get_value(time_grid)\n",
    "\n",
    "# Get the median modes\n",
    "gp.set_parameter_vector(samples[np.argmax(log_probs)])\n",
    "peak_freqs = gp.kernel.terms[0].get_freqs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot constraints on nu-max and delta-nu\n",
    "i = [names.index(\"log(nu max)\"), names.index(\"log(delta nu)\")]\n",
    "s = np.exp(samples[:, i])/uHz_conv\n",
    "nu_max_pub = 171.94, 3.62\n",
    "delta_nu_pub = 13.28, 0.29\n",
    "fig = corner.corner(s, smooth=0.7, smooth1d=1.0,\n",
    "                    labels=[r\"$\\nu_\\mathrm{max}$\", r\"$\\Delta \\nu$\"])\n",
    "fig.axes[2].errorbar(nu_max_pub[0], delta_nu_pub[0],\n",
    "                     xerr=nu_max_pub[1], yerr=delta_nu_pub[1],\n",
    "                     fmt=\".\", color=COLORS[\"MODEL_1\"], capsize=0,\n",
    "                     lw=2, mec=\"none\")\n",
    "ax = fig.axes[0]\n",
    "y = np.mean(ax.get_ylim())\n",
    "ax.errorbar(nu_max_pub[0], y, xerr=nu_max_pub[1],\n",
    "            fmt=\".\", color=COLORS[\"MODEL_1\"], capsize=0,\n",
    "            lw=2, mec=\"none\")\n",
    "\n",
    "ax = fig.axes[3]\n",
    "y = np.mean(ax.get_ylim())\n",
    "ax.errorbar(delta_nu_pub[0], y, xerr=delta_nu_pub[1],\n",
    "            fmt=\".\", color=COLORS[\"MODEL_1\"], capsize=0,\n",
    "            lw=2, mec=\"none\")\n",
    "\n",
    "fig.savefig(\"astero-corner.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(samples, smooth=0.7, smooth1d=1.0, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import cho_solve, cho_factor\n",
    "\n",
    "p0 = gp.get_parameter_vector()\n",
    "fast_timing = %timeit -o log_prob(p0)\n",
    "\n",
    "def _time_this():\n",
    "    K = gp.get_matrix(include_diagonal=True)\n",
    "    factor = cho_factor(K, overwrite_a=True)\n",
    "    ld = 2.0 * np.sum(np.log(np.diag(factor[0])))\n",
    "    ll = -0.5*(np.dot(fit_y, cho_solve(factor, fit_y))+ld) + gp.log_prior()\n",
    "\n",
    "slow_timing = %timeit -o _time_this()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = sampler.get_coords(discard=5000)[:, :, [ind_nu_max, ind_delta_nu]]\n",
    "tau = np.mean(autocorr.integrated_time(np.mean(chain, axis=1), c=5))\n",
    "neff = len(samples) / tau\n",
    "tau, neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "c = gp.kernel.coefficients\n",
    "with open(\"astero.json\", \"w\") as f:\n",
    "    json.dump(dict(\n",
    "        N=len(fit_x),\n",
    "        J=len(c[0]) + len(c[2]),\n",
    "        tau=tau,\n",
    "        neff=neff,\n",
    "        time=fast_timing.average,\n",
    "        direct_time=slow_timing.average,\n",
    "        nwalkers=nwalkers,\n",
    "        nburn=5000,\n",
    "        nsteps=15000,\n",
    "        ndim=int(ndim),\n",
    "    ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    'kernel:terms[0]:log_S_g': \"$\\ln(S_g/\\mathrm{ppm}^2)$\",\n",
    "    'kernel:terms[0]:log_omega_g': \"$\\ln(\\omega_g/\\mathrm{day}^{-1})$\",\n",
    "    'kernel:terms[0]:log_nu_max': \"\",\n",
    "    'kernel:terms[0]:log_delta_nu': \"\",\n",
    "    'kernel:terms[0]:epsilon': \"\",\n",
    "    'kernel:terms[0]:log_A': \"$\\ln(A/\\mathrm{ppm}^2\\,\\mathrm{day})$\",\n",
    "    'kernel:terms[0]:log_Q': \"$\\ln(Q)$\",\n",
    "    'kernel:terms[0]:log_W': \"$\\ln(W/\\mathrm{day}^{-1})$\",\n",
    "    'kernel:terms[1]:log_sigma': \"$\\ln(\\sigma/\\mathrm{ppm})$\",\n",
    "}\n",
    "params = list(zip(\n",
    "    (name_map[n] for n in gp.get_parameter_names()),\n",
    "    gp.get_parameter_bounds()\n",
    "))\n",
    "params[ind_nu_max] = r\"$\\ln(\\nu_\\mathrm{max}/\\mu\\mathrm{Hz})$\", [\"\\ln(130)\", \"\\ln(190)\"]\n",
    "params[ind_delta_nu] = r\"$\\ln(\\Delta \\nu/\\mu\\mathrm{Hz})$\", [\"\\ln(12.5)\", \"\\ln(13.5)\"]\n",
    "params[ind_delta_nu+1] = \"$\\epsilon/\\mathrm{day}^{-1}$\", [\"$\\mathcal{N}(0,\\,1)$\"]\n",
    "with open(\"astero-params.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make comparison plot\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, sharey=True,\n",
    "                         figsize=get_figsize(2.5, 2))\n",
    "\n",
    "axes[0].plot(freq_uHz, power_all, \"k\", rasterized=True)\n",
    "axes[0].plot(freq_uHz, gaussian_filter(power_all, 150),\n",
    "             color=COLORS[\"MODEL_2\"], rasterized=True)\n",
    "axes[0].axhline(white_noise_all)\n",
    "\n",
    "axes[1].plot(freq_uHz, power_some, \"k\", rasterized=True)\n",
    "axes[1].plot(freq_uHz, gaussian_filter(power_some, 450),\n",
    "             color=COLORS[\"MODEL_2\"], rasterized=True)\n",
    "axes[1].axhline(white_noise_some)\n",
    "\n",
    "q = np.percentile(uHz_conv/(2*np.pi)*psds, [16, 50, 84], axis=0)\n",
    "axes[2].fill_between(freq_uHz, q[0], q[2], color=\"k\", alpha=0.3,\n",
    "                     rasterized=True)\n",
    "axes[2].plot(freq_uHz, q[1], \"k\", alpha=0.8, rasterized=True)\n",
    "axes[2].axhline(white_noise_some)\n",
    "\n",
    "labels = [\n",
    "    \"periodogram estimator\\n4 years of data\",\n",
    "    \"periodogram estimator\\n1 month of data\",\n",
    "    \"posterior inference\\n1 month of data\",\n",
    "]\n",
    "for ax, label in zip(axes, labels):\n",
    "    ax.set_yscale(\"log\")\n",
    "    for f in peak_freqs / uHz_conv:\n",
    "        ax.plot([f, f], [2e2, 3e2], \"k\", lw=0.5)\n",
    "    ax.annotate(label, xy=(1, 1), xycoords=\"axes fraction\",\n",
    "                ha=\"right\", va=\"top\",\n",
    "                xytext=(-5, -5), textcoords=\"offset points\",\n",
    "                fontsize=12)\n",
    "    ax.set_ylabel(\"power [$\\mathrm{ppm}^2\\,\\mu\\mathrm{Hz}^{-1}$]\")\n",
    "\n",
    "axes[2].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "axes[2].set_xlim(freq_uHz.min(), freq_uHz.max())\n",
    "axes[2].set_ylim(1e-3, 4e2)\n",
    "\n",
    "fig.savefig(\"astero-comp.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.set_parameter_vector(samples[np.argmax(log_probs)])\n",
    "t0 = fit_x.min()\n",
    "x = np.linspace(t0+9.5, t0+20.5, 1000)\n",
    "mu, var = gp.predict(fit_y, x, return_var=True)\n",
    "std = np.sqrt(var)\n",
    "\n",
    "pred_mu, pred_var = gp.predict(fit_y, return_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=plot_setup.get_figsize(1, 2))\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 2), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 2), (2, 0), rowspan=1)\n",
    "fig.subplots_adjust(hspace=0, wspace=0.1)\n",
    "\n",
    "ax1.errorbar(fit_x - t0, fit_y, yerr=fit_yerr, fmt=\".k\",\n",
    "             lw=0.5, ms=3, rasterized=True)\n",
    "ax1.plot(x - t0, mu, lw=0.75, rasterized=True)\n",
    "ax1.fill_between(x-t0, mu+std, mu-std, alpha=0.5, edgecolor=\"none\", zorder=100)\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax1.annotate(\"N = {0}\".format(len(fit_x)), xy=(0, 1),\n",
    "             xycoords=\"axes fraction\",\n",
    "             xytext=(5, -5), textcoords=\"offset points\",\n",
    "             ha=\"left\", va=\"top\")\n",
    "\n",
    "sig = np.sqrt(fit_yerr**2 + pred_var)\n",
    "ax2.errorbar(fit_x - t0, fit_y - pred_mu, yerr=sig, fmt=\".k\",\n",
    "             ms=3, lw=0.5, rasterized=True)\n",
    "ax2.axhline(0.0, color=\"k\", lw=0.75)\n",
    "\n",
    "ax1.set_ylim(-750, 750)\n",
    "ax1.set_xlim(9.5, 20.5)\n",
    "ax2.set_ylim(-245, 245)\n",
    "ax2.set_xlim(9.5, 20.5)\n",
    "\n",
    "ax2.set_xlabel(\"time [day]\")\n",
    "ax1.set_ylabel(\"relative flux [ppm]\")\n",
    "ax2.set_ylabel(\"residuals\")\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.yaxis.set_label_coords(-0.22, 0.5)\n",
    "    \n",
    "fig.savefig(\"astero.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}