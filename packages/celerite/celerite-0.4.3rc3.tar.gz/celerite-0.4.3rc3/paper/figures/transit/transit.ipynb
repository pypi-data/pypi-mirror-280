{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "from celerite import plot_setup\n",
    "plot_setup.setup(auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kplr\n",
    "import copy\n",
    "import emcee3\n",
    "import pickle\n",
    "import fitsio\n",
    "import corner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import transit\n",
    "\n",
    "from celerite.plot_setup import setup, get_figsize, COLORS\n",
    "\n",
    "import celerite\n",
    "from celerite import terms, modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationTerm(terms.Term):\n",
    "    parameter_names = (\"log_amp\", \"log_timescale\", \"log_period\", \"log_factor\")\n",
    "\n",
    "    def get_real_coefficients(self, params):\n",
    "        log_amp, log_timescale, log_period, log_factor = params\n",
    "        f = np.exp(log_factor)\n",
    "        return (\n",
    "            np.exp(log_amp) * (1.0 + f) / (2.0 + f),\n",
    "            np.exp(-log_timescale),\n",
    "        )\n",
    "\n",
    "    def get_complex_coefficients(self, params):\n",
    "        log_amp, log_timescale, log_period, log_factor = params\n",
    "        f = np.exp(log_factor)\n",
    "        return (\n",
    "            np.exp(log_amp) / (2.0 + f),\n",
    "            0.0,\n",
    "            np.exp(-log_timescale),\n",
    "            2*np.pi*np.exp(-log_period),\n",
    "        )\n",
    "\n",
    "class TransitModel(modeling.Model):\n",
    "    parameter_names = (\"mean_flux\", \"log_period\", \"log_ror\", \"log_duration\",\n",
    "                       \"t0\", \"impact\", \"q1\", \"q2\")\n",
    "\n",
    "    def __init__(self, texp, *args, **kwargs):\n",
    "        self.texp = texp\n",
    "        super(TransitModel, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def get_value(self, t):\n",
    "        system = transit.SimpleSystem(\n",
    "            period=np.exp(self.log_period),\n",
    "            ror=np.exp(self.log_ror),\n",
    "            duration=np.exp(self.log_duration),\n",
    "            t0=self.t0,\n",
    "            impact=self.impact,\n",
    "            q1=self.q1,\n",
    "            q2=self.q2\n",
    "        )\n",
    "        lc = system.light_curve(t, texp=self.texp)\n",
    "        return 1e3 * (lc - 1.0) + self.mean_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(auto=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "data = fitsio.read(\"../data/kplr001430163-2013011073258_llc.fits\")\n",
    "texp = 1625.3467838829 / 60. / 60. / 24.\n",
    "\n",
    "N = 1000\n",
    "m = data[\"SAP_QUALITY\"] == 0\n",
    "m &= np.isfinite(data[\"TIME\"])\n",
    "m &= np.isfinite(data[\"PDCSAP_FLUX\"])\n",
    "t = np.ascontiguousarray(data[\"TIME\"][m], dtype=np.float64)[:N]\n",
    "y = np.ascontiguousarray(data[\"PDCSAP_FLUX\"][m], dtype=np.float64)[:N]\n",
    "yerr = np.ascontiguousarray(data[\"PDCSAP_FLUX_ERR\"][m], dtype=np.float64)[:N]\n",
    "t -= 0.5 * (t.min() + t.max())\n",
    "\n",
    "# Build the true model\n",
    "true_model = TransitModel(\n",
    "    texp,\n",
    "    0.0,\n",
    "    np.log(8.0),    # period\n",
    "    np.log(0.015),  # Rp / Rs\n",
    "    np.log(0.5),    # duration\n",
    "    0.0,            # t_0\n",
    "    0.5,            # impact\n",
    "    0.5,            # q_1\n",
    "    0.5,            # q_2\n",
    ")\n",
    "true_params = np.array(true_model.get_parameter_vector())\n",
    "\n",
    "# Inject the transit into the data\n",
    "true_transit = 1e-3*true_model.get_value(t) + 1.0\n",
    "y *= true_transit\n",
    "\n",
    "# Normalize the data\n",
    "med = np.median(y)\n",
    "y = (y / med - 1.0) * 1e3\n",
    "yerr *= 1e3 / med\n",
    "\n",
    "# Set up the GP model\n",
    "mean = TransitModel(\n",
    "    texp,\n",
    "    0.0,\n",
    "    np.log(8.0),\n",
    "    np.log(0.015),\n",
    "    np.log(0.5),\n",
    "    0.0,\n",
    "    0.5,\n",
    "    0.5,\n",
    "    0.5,\n",
    "    bounds=[\n",
    "        (-0.5, 0.5),\n",
    "        np.log([7.9, 8.1]),\n",
    "        (np.log(0.005), np.log(0.1)),\n",
    "        (np.log(0.4), np.log(0.6)),\n",
    "        (-0.1, 0.1),\n",
    "        (0, 1.0), (0, 1), (0, 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "kernel = RotationTerm(\n",
    "    np.log(np.var(y)), np.log(0.5*t.max()), np.log(4.5), 0.0,\n",
    "    bounds=dict(\n",
    "        log_amp=(-10.0, 0.0),\n",
    "        log_timescale=(1.5, 5.0),\n",
    "        log_period=(-3.0, 5.0),\n",
    "        log_factor=(-5.0, 5.0),\n",
    "    ),\n",
    ")\n",
    "kernel += terms.JitterTerm(\n",
    "    log_sigma=np.log(0.5*yerr.min()),\n",
    "    bounds=[(-5.0, 0.0)],\n",
    ")\n",
    "\n",
    "gp = celerite.GP(kernel, mean=mean, fit_mean=True)\n",
    "gp.compute(t, yerr)\n",
    "print(\"Initial log-likelihood: {0}\".format(gp.log_likelihood(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_like(params, y, gp):\n",
    "    gp.set_parameter_vector(params)\n",
    "    return -gp.log_likelihood(y)\n",
    "\n",
    "# Optimize with random restarts\n",
    "p0 = gp.get_parameter_vector()\n",
    "bounds = gp.get_parameter_bounds()\n",
    "r = minimize(neg_log_like, p0, method=\"L-BFGS-B\", bounds=bounds, args=(y, gp))\n",
    "gp.set_parameter_vector(r.x)\n",
    "ml_params = np.array(r.x)\n",
    "print(\"Maximum log-likelihood: {0}\".format(gp.log_likelihood(y)))\n",
    "\n",
    "# Compute the maximum likelihood predictions\n",
    "x = np.linspace(t.min(), t.max(), 5000)\n",
    "trend = gp.predict(y, t, return_cov=False)\n",
    "trend -= gp.mean.get_value(t) - gp.mean.mean_flux\n",
    "mu, var = gp.predict(y, x, return_var=True)\n",
    "std = np.sqrt(var)\n",
    "mean_mu = gp.mean.get_value(x)\n",
    "mu -= mean_mu\n",
    "wn = np.exp(2*gp.kernel.terms[1].log_sigma)\n",
    "ml_yerr = np.sqrt(yerr**2 + wn)\n",
    "\n",
    "# Plot the maximum likelihood predictions\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=get_figsize(1, 2))\n",
    "ax1.errorbar(t - t.min(), y, yerr=ml_yerr, fmt=\".k\", capsize=0, zorder=-1)\n",
    "ax1.plot(x - t.min(), mu, zorder=100)\n",
    "ax1.set_ylim(-0.72, 0.72)\n",
    "ax1.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax1.set_ylabel(\"raw [ppt]\")\n",
    "ax1.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "ax2.errorbar(t - t.min(), y-trend, yerr=ml_yerr, fmt=\".k\", capsize=0,\n",
    "             zorder=-1)\n",
    "ax2.plot(x - t.min(), mean_mu - gp.mean.mean_flux, zorder=100)\n",
    "ax2.set_xlim(0, t.max()-t.min())\n",
    "ax2.set_ylim(-0.41, 0.1)\n",
    "\n",
    "ax2.annotate(\"N = {0}\".format(len(t)), xy=(0, 0),\n",
    "             xycoords=\"axes fraction\",\n",
    "             xytext=(5, 5), textcoords=\"offset points\",\n",
    "             ha=\"left\", va=\"bottom\")\n",
    "\n",
    "ax2.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax2.set_ylabel(\"de-trended [ppt]\")\n",
    "ax2.set_xlabel(\"time [days]\")\n",
    "ax2.yaxis.set_label_coords(-0.1, 0.5)\n",
    "fig.savefig(\"transit-ml.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transit.pkl\", \"wb\") as f:\n",
    "    pickle.dump((gp, y, true_model.get_parameter_dict()), f, -1)\n",
    "\n",
    "# Do the MCMC\n",
    "def log_prob(params):\n",
    "    gp.set_parameter_vector(params)\n",
    "    lp = gp.log_prior()\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return gp.log_likelihood(y) + lp\n",
    "\n",
    "# Initialize\n",
    "print(\"Running MCMC sampling...\")\n",
    "ndim = len(ml_params)\n",
    "nwalkers = 32\n",
    "pos = ml_params + 1e-5 * np.random.randn(nwalkers, ndim)\n",
    "lp = np.array(list(map(log_prob, pos)))\n",
    "m = ~np.isfinite(lp)\n",
    "while np.any(m):\n",
    "    pos[m] = ml_params + 1e-5 * np.random.randn(m.sum(), ndim)\n",
    "    lp[m] = np.array(list(map(log_prob, pos[m])))\n",
    "    m = ~np.isfinite(lp)\n",
    "\n",
    "# Sample\n",
    "sampler = emcee3.Sampler(backend=emcee3.backends.HDFBackend(\"transit.h5\"))\n",
    "with emcee3.pools.InterruptiblePool() as pool:\n",
    "    ensemble = emcee3.Ensemble(emcee3.SimpleModel(log_prob), pos, pool=pool)\n",
    "    sampler.run(ensemble, 30000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = true_model.get_parameter_dict()\n",
    "names = gp.get_parameter_names()\n",
    "cols = [\"log_period\", \"log_ror\", \"log_duration\", \"t0\"]\n",
    "inds = [names.index(\"mean:{0}\".format(c)) for c in cols]\n",
    "samples = np.array(sampler.get_coords(discard=10000, flat=True, thin=7))\n",
    "samples = samples[:, inds]\n",
    "samples[:, :-1] = np.exp(samples[:, :-1])\n",
    "truths = np.array([true_params[k] for k in cols])\n",
    "truths[:-1] = np.exp(truths[:-1])\n",
    "fig = corner.corner(samples, truths=truths, smooth=0.5,\n",
    "                    labels=[r\"period\", r\"$R_\\mathrm{P}/R_\\star$\", r\"duration\",\n",
    "                            r\"$t_0$\"])\n",
    "for ax in np.array(fig.axes).flatten():\n",
    "    ax.xaxis.set_label_coords(0.5, -0.4)\n",
    "    ax.yaxis.set_label_coords(-0.4, 0.5)\n",
    "fig.savefig(\"transit-corner.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sampler.get_coords()[:, :, names.index(\"mean:impact\")]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import cho_solve, cho_factor\n",
    "\n",
    "p0 = gp.get_parameter_vector()\n",
    "fast_timing = %timeit -o log_prob(p0)\n",
    "\n",
    "def _time_this():\n",
    "    K = gp.get_matrix(include_diagonal=True)\n",
    "    factor = cho_factor(K, overwrite_a=True)\n",
    "    ld = 2.0 * np.sum(np.log(np.diag(factor[0])))\n",
    "    resid = gp.mean.get_value(t) - y\n",
    "    ll = -0.5*(np.dot(resid, cho_solve(factor, resid))+ld) + gp.log_prior()\n",
    "\n",
    "slow_timing = %timeit -o _time_this()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.get_coords(discard=10000, flat=True)\n",
    "names = gp.get_parameter_names()\n",
    "chain = sampler.get_coords(discard=10000)[:, :, names.index(\"mean:log_period\")]\n",
    "tau = np.mean(emcee3.autocorr.integrated_time(np.mean(chain, axis=1), c=5))\n",
    "neff = len(samples) / tau\n",
    "tau, neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "c = gp.kernel.coefficients\n",
    "with open(\"transit.json\", \"w\") as f:\n",
    "    json.dump(dict(\n",
    "        N=len(t),\n",
    "        J=len(c[0]) + len(c[2]),\n",
    "        tau=tau,\n",
    "        neff=neff,\n",
    "        time=fast_timing.average,\n",
    "        direct_time=slow_timing.average,\n",
    "        nwalkers=nwalkers,\n",
    "        nburn=10000,\n",
    "        nsteps=30000,\n",
    "        ndim=ndim,\n",
    "    ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    'kernel:terms[0]:log_amp': \"$\\ln(B/\\mathrm{ppt}^2)$\",\n",
    "    'kernel:terms[0]:log_timescale': \"$\\ln(L/\\mathrm{day})$\",\n",
    "    'kernel:terms[0]:log_period': \"$\\ln(P_\\mathrm{rot}/\\mathrm{day})$\",\n",
    "    'kernel:terms[0]:log_factor': \"$\\ln(C)$\",\n",
    "    'kernel:terms[1]:log_sigma': \"$\\ln(\\sigma/\\mathrm{ppt})$\",\n",
    "    'mean:mean_flux': \"$f_0/\\mathrm{ppt}$\",\n",
    "    'mean:log_period': \"$\\ln(P_\\mathrm{orb}/\\mathrm{day})$\",\n",
    "    'mean:log_ror': \"$\\ln(R_p/R_\\star)$\",\n",
    "    'mean:log_duration': \"$\\ln(T/\\mathrm{day})$\",\n",
    "    'mean:t0': \"$t_0/\\mathrm{day}$\",\n",
    "    'mean:impact': \"$b$\",\n",
    "    'mean:q1': \"$q_1$\",\n",
    "    'mean:q2': \"$q_2$\",\n",
    "}\n",
    "params = list(zip(\n",
    "    (name_map[n] for n in gp.get_parameter_names()),\n",
    "    gp.get_parameter_bounds()\n",
    "))\n",
    "\n",
    "params[6] = \"$\\ln(P_\\mathrm{orb}/\\mathrm{day})$\", [\"\\ln(7.9)\", \"\\ln(8.1)\"]\n",
    "params[7] = \"$\\ln(R_p/R_\\star)$\", [\"\\ln(0.005)\", \"\\ln(0.1)\"]\n",
    "params[8] = \"$\\ln(T/\\mathrm{day})$\", [\"\\ln(0.4)\", \"\\ln(0.6)\"]\n",
    "with open(\"transit-params.json\", \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}