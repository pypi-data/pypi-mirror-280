Metadata-Version: 2.1
Name: altrumai
Version: 1.0.0
Summary: A python client for interacting with AltrumAI APIs.
Home-page: UNKNOWN
Author: Yashwanth S
Author-email: yashwanth@aligne.ai
License: Apache-v2
Keywords: altrumai api client aligne
Platform: UNKNOWN
Description-Content-Type: text/markdown
License-File: LICENSE

# AltrumAI Python API library

The AltrumAI Python library provides convenient access to the AltrumAI REST API from any Python 3.7+
application. The library includes type definitions for all request params and response fields,
and offers synchronous and asynchronous client powered by [requests](https://github.com/psf/requests).

## Documentation

The REST API direct access and its documentation is still being worked upon.

## Installation

> [!IMPORTANT]
> The Altrum AI Python SDK is not public and is only available for internal aligne use or our customers (On request) at the moment.

```sh
pip install altrumai
```

## Usage

```python
import os
from altrumai import AltrumAI
from dotenv import load_dotenv

load_dotenv()

def get_models():

    # Initialise AltrumAI client
    client = AltrumAI(
        workspace=os.getenv("WORKSPACE_ID"),
        base_url=os.getenv("DEPLOYMENT_URL"),
        api_key=os.getenv("ALIGNEAI_API_KEY")
        )
    # Generate chat completion using AltrumAI
    response = client.models()

    # Log the response into your stdout
    print(response.text)

if __name__ == "__main__":
    get_models()
```

## Async Usage

```python
import os
from altrumai import AsyncAltrumAI
from dotenv import load_dotenv
import asyncio

load_dotenv()

async def get_models():

    # Initialise AltrumAI client
    client = AsyncAltrumAI(
        workspace=os.getenv("WORKSPACE_ID"),
        base_url=os.getenv("DEPLOYMENT_URL"),
        api_key=os.getenv("ALIGNEAI_API_KEY")
        )

    # Generate chat completion using AltrumAI
    response = await client.models()

    # Log the response into your stdout
    print(response.text)

if __name__ == "__main__":
    asyncio.run(get_models())
```

## Models

List and describe the various models available in the API.

above usage code will give the list of all the available models

Paramenters : none

## Deployments

List and describe the various models available in your workspace.

```python
response = client.deployments()
```
Paramenters : none

## Privacy

Detect entities as per data privacy compliance laws.

```python
response = client.privacy(
        input="The UK company Steeper (http://bebionic.com/) is producing cutting edge electronic hands for amputees which feature over a dozen grip patterns, wrist mobility, and speed control - all through the muscle pressure sensors located in the device’s casing.",
        compliance= ["GDPR","HIPAA"],
        custom=["Money", "File Name"]
)
```
Parameters :

* input (str): The input text that needs to be checked for privacy compliance.
* compliance (list): A list of standard compliance regulations to check against. Supported values include:
    Supported values : ["GDPR" "HIPAA"]
* custom (list): A list of custom compliance rules to apply
    Supported values : ["Money" "Filename", "Account Number", "Password", "Marital Status", "Organization", "Dosage"]

## Chat Completions

Given a list of messages comprising a conversation, the model will return a response.

```python
response = client.chat_completion(
    model="mistral-7b-chat",
    messages=[{'role': 'user', 'content': "What are different types of emerging risks related to AI?"}],
    stream=False,
    timeout=60
)
```

Parameters :

* model (str): The name of the model to be used for generating responses(can get the list from client.models).
* messages (list): A list of message objects, each containing:
    role (str): The role of the message sender. Valid roles are:
                    "user"
                    "assistant"
    content (str): The content of the message.
* stream (bool, optional): If set to True, the response will be streamed as it is generated. Defaults to False.

## Moderations

Detect toxicity and bias for moderations.

```python
response = client.moderations(
        input="The UK company Steeper (http://bebionic.com/) is producing cutting edge electronic hands for amputees which feature over a dozen grip patterns, wrist mobility, and speed control - all through the muscle pressure sensors located in the device’s casing.",
        guardrails= ["bias","toxicity"]
)
```
Parameters :

* input (str): The input text that needs to be moderated.
* guardrails (list): A list of guardrails to check the input text against. Supported values include:
                    "bias"
                    "toxicity"

## Embeddings

Creates an embedding vector representing the input text.

```python
response = client.create_embeddings(
    inputs=["The new coffee blend from BeanWorks is robust and flavorful"],
    model="nomic-embed-v1.5",
    dimensions=64,
    encoding_format="float",
)
```

Parameters :

* inputs (list): A list of input texts for which embeddings need to be generated.
* model (str): The name of the model to be used for generating embeddings(can get the list from client.models).
* dimensions (int): The number of dimensions for the generated embeddings. Supported values : 64, 128, 256, 512, 768
* encoding_format (str): The format of the embedding values. Supported value: "float".

## Ping

Endpoint to verify your Workspace ID and API Key on AltrumAI

```python
ping_response = client.ping()
```

## Timeouts

Currently by default 60 sec timeout is set for post methods, but timeout can be passed as a parameter while calling any method.

```python
response = client.deployments(timeout=60)
```

## Module-level client

We recommend that you always instantiate a client (e.g., with `client = AltrumAI()`) in application code.

## Handling errors

When the library is unable to connect to the API (for example, due to network connection problems or a timeout), a subclass of `altrumai.APIConnectionError` will be raised.

When the API returns a non-success status code (that is, 4xx or 5xx
response), a subclass of `altrumai.APIStatusError` is raised, containing `status_code` and `response` properties.

All errors inherit from `altrumai.APIError`.

Error codes are as followed:

| Status Code | Error Type                 |
| ----------- | -------------------------- |
| 400         | `BadRequestError`          |
| 401         | `AuthenticationError`      |
| 403         | `PermissionDeniedError`    |
| 404         | `NotFoundError`            |
| 422         | `UnprocessableEntityError` |
| 429         | `RateLimitError`           |
| >=500       | `InternalServerError`      |
| N/A         | `APIConnectionError`       |

(Work In Progress)

### Retries

Certain errors are automatically retried 2 times by default, with a short exponential backoff.
Connection errors (for example, due to a network connectivity problem), 408 Request Timeout, 409 Conflict,
429 Rate Limit, and >=500 Internal errors are all retried by default.

You can use the `max_retries` option to configure or disable retry settings. (Work In Progress)

## Versioning

This package generally follows [SemVer](https://semver.org/spec/v2.0.0.html) conventions, though certain backwards-incompatible changes may be released as minor versions:

1. Changes that only affect static types, without breaking runtime behavior.
2. Changes to library internals which are technically public but not intended or documented for external use. _(Please open a GitHub issue to let us know if you are relying on such internals)_.
3. Changes that we do not expect to impact the vast majority of users in practice.

We take backwards-compatibility seriously and work hard to ensure you can rely on a smooth upgrade experience.

We are keen for your feedback; please open an [issue](https://www.github.com/aligne/altrumai-python/issues) with questions, bugs, or suggestions.

